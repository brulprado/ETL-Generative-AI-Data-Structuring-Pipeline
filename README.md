# ETL-Generative-AI-Data-Structuring-Pipeline
Pipeline ETL em Python que utiliza simula√ß√£o de LLM para transformar dados textuais brutos (feedback) em um formato estruturado pronto para BI

**Autora:** Bruna Lima Prado

# üöÄ ETL de Alto Desempenho com IA Generativa para Estrutura√ß√£o de Dados N√£o Estruturados

## Vis√£o Geral

Este projeto demonstra a constru√ß√£o de um pipeline de **Engenharia de Dados (ETL)** robusto e desacoplado, utilizando a filosofia de **IA Generativa** para transformar dados textuais brutos e n√£o estruturados (Feedback de Clientes) em dados tabulares prontos para Business Intelligence (BI).

Em um contexto onde o volume de dados textuais excede a capacidade de an√°lise manual, a solu√ß√£o substitui m√©todos complexos de NLP por um √∫nico componente de **Large Language Model (LLM)**, focado em **Data Structuring**. Para garantir portabilidade, efici√™ncia e controle de custos, a transforma√ß√£o LLM √© simulada de forma local, preparada para migrar facilmente para solu√ß√µes *on-premise* como **Llama 3** ou **Mistral** via vLLM.

## üéØ Desafio de Neg√≥cio & Inova√ß√£o

### O Problema
A complexidade de analisar milhares de feedbacks de clientes diariamente resulta em alto *time-to-insight* e custos operacionais elevados. Regras tradicionais de Processamento de Linguagem Natural (NLP) s√£o fr√°geis e exigem manuten√ß√£o constante.

### A Solu√ß√£o (O Brilho)
Implementamos uma arquitetura de pipeline que encapsula a l√≥gica de neg√≥cio na fase de transforma√ß√£o. O componente de IA Generativa n√£o apenas extrai o sentimento, mas tamb√©m **cria categorias e resumos sint√©ticos**, transformando uma *string* de texto em uma linha de dados totalmente estruturada e consum√≠vel.

* **Zero-Shot Structuring:** A IA realiza a categoriza√ß√£o sem treinamento pr√©vio (simulando um *prompt* eficiente).
* **Desacoplamento:** O pipeline √© independente de APIs externas (como OpenAI), focando em uma solu√ß√£o escal√°vel e control√°vel em ambiente de produ√ß√£o.

## üß† Arquitetura do Pipeline (ETL)

O pipeline segue a estrutura cl√°ssica E-T-L, com foco na modularidade e resili√™ncia:

### 1. **E**xtraction (`src/extract.py`)
* **Fonte de Dados:** Simula√ß√£o de extra√ß√£o de uma fonte de dados massiva (e.g., S3/Data Lake) via arquivo CSV.
* **Fun√ß√£o:** Coleta de `id_feedback`, `id_produto` e o campo crucial de `texto_feedback` bruto.

### 2. **T**ransformation (`src/transform.py`)
* **Tecnologia:** Simula√ß√£o de um **LLM local** (fun√ß√£o heur√≠stica robusta).
* **Processo:**
    * **An√°lise de Sentimento:** Classifica√ß√£o em Positivo, Negativo ou Neutro.
    * **Classifica√ß√£o Tem√°tica:** Categoriza√ß√£o em Performance, Design ou Pre√ßo.
    * **Resumo Sint√©tico:** Gera√ß√£o de um resumo conciso do feedback.
* **Robustez:** Implementa√ß√£o de `try...except` e *fallbacks* para simular resili√™ncia contra falhas de infer√™ncia ou *rate limits*.

### 3. **L**oad (`src/load.py`)
* **Destino:** Carregamento dos dados estruturados em formato JSON (simulando um *staging area* ou um **Data Warehouse** como Snowflake/BigQuery).
* **Formato:** Dados prontos para consumo por ferramentas de BI (Tableau, PowerBI).

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem Principal:** Python 3.10+
* **Bibliotecas:** Pandas (Processamento de Dados), JSON (Carregamento).
* **Conceitos Arquiteturais:** Modulariza√ß√£o de C√≥digo (S√™nior), Resili√™ncia e Tratamento de Exce√ß√µes, Data Structuring com LLMs.
* **Ferramentas:** Apache Airflow/Prefect (Orquestra√ß√£o), Docker (Empacotamento), vLLM/Ollama (Infer√™ncia Otimizada).

## ‚öôÔ∏è Como Executar o Projeto

### Pr√©-requisitos
Certifique-se de ter Python instalado.

1.  **Clone o Reposit√≥rio:**
    ```bash
    git clone [(https://github.com/brulprado)]
    cd ETL-Generative-AI-Feedback-Analysis
    ```

2.  **Crie e Ative o Ambiente Virtual:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # ou venv\Scripts\activate no Windows
    ```

3.  **Instale as Depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Execute o Pipeline Principal:**
    ```bash
    python src/main_pipeline.py
    ```
    O resultado estruturado ser√° salvo em `data/structured_data.json`.

## üìä An√°lise de Resultados (Data Storytelling)

Consulte o notebook **`notebooks/ETL_Data_Storytelling.ipynb`** para uma visualiza√ß√£o completa.

| Atributo | Antes (Dados Brutos) | Depois (Dados Estruturados) |
| :--- | :--- | :--- |
| **Formato** | Texto Livre (`string`) | JSON/Tabular (`dict`) |
| **Valor** | N√£o Acion√°vel | Sentimento, Categoria, Resumo |
| **Exemplo de Valor Agregado** | *O pre√ßo √© alto, mas a performance compensa.* | **Sentimento:** Positivo | **Categoria:** Pre√ßo/Performance |
