**1. üéØ Introdu√ß√£o e Setup**

# An√°lise de Insights de Clientes Gerados por LLM
# Autor: Bruna Lima Prado
# Data: 20/11/2025

# Objetivo: Validar o pipeline ETL, carregando e analisando os dados estruturados
# gerados pela fase de Transforma√ß√£o (IA Generativa) para extrair insights de neg√≥cio.

# Importa√ß√µes Essenciais para An√°lise de Dados e Visualiza√ß√£o
import pandas as pd
import json
import matplotlib.pyplot as plt
import seaborn as sns

# Configura√ß√£o de Estilo
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)

print("Setup de bibliotecas conclu√≠do.")

2. üì• Carregamento e Inspe√ß√£o dos Dados Estruturados
Demonstra√ß√£o do carregamento do output do pipeline.

# Caminho do arquivo JSON gerado pelo pipeline (LOAD)
FILE_PATH = '../data/structured_data.json'

try:
    with open(FILE_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)
        df = pd.DataFrame(data)
    
    print(f"‚úÖ Sucesso! Dados carregados a partir de: {FILE_PATH}")
except FileNotFoundError:
    print(f"‚ùå ERRO: Arquivo n√£o encontrado. Verifique se o pipeline foi executado e se o arquivo est√° em '{FILE_PATH}'.")
    df = pd.DataFrame() # Cria um DataFrame vazio em caso de erro

# Exibir as primeiras linhas e tipos de dados
if not df.empty:
    print("\n--- Inspe√ß√£o Inicial dos Dados Estruturados ---")
    display(df.head())
    print("\n--- Tipos de Dados ---")
    df.info()

**3. ‚ú® Valida√ß√£o da Transforma√ß√£o (Prova de Valor do LLM)**
Mostra como o LLM (simulado) transformou texto bruto em categorias acion√°veis.

# Gerando o DataFrame para mostrar o Antes (simulado) vs. Depois (carregado)
# Nota: Como o texto original n√£o est√° no JSON de sa√≠da, recriamos uma amostra
dados_comparacao = {
    'id_feedback': [101, 102, 103, 104],
    'Texto Original (Simulado)': [
        "A bateria dura o dia todo, adorei! Mas o design √© um pouco sem gra√ßa.",
        "O pre√ßo √© muito alto para a qualidade. Estou desapontado com a performance.",
        "Produto excelente, superou minhas expectativas. R√°pido e f√°cil de usar.",
        "Gostei da cor, mas a performance em jogos √© fraca."
    ]
}
df_original = pd.DataFrame(dados_comparacao)

if not df.empty:
    df_comparacao = pd.merge(df_original, df, on='id_feedback', how='inner')
    df_comparacao = df_comparacao[['Texto Original (Simulado)', 'Sentimento', 'Categoria', 'Resumo_IA']]

    print("\n--- Valida√ß√£o: Transforma√ß√£o de Texto N√£o Estruturado ---")
    from IPython.display import display
    display(df_comparacao)
    print("\nO pipeline LLM estruturou o feedback, gerando Sentimento, Categoria e um Resumo conciso, pronto para an√°lise quantitativa.")

**4. üìà An√°lise Quantitativa e Visualiza√ß√µes**
**A. Distribui√ß√£o de Sentimento**

if not df.empty:
    plt.figure(figsize=(8, 5))
    sns.countplot(x='Sentimento', data=df, palette='viridis', order=df['Sentimento'].value_counts().index)
    plt.title('Distribui√ß√£o de Sentimentos dos Clientes')
    plt.xlabel('Sentimento')
    plt.ylabel('Contagem de Feedbacks')
    plt.show()

    # Insight 1: Propor√ß√£o
    proporcao_sentimento = df['Sentimento'].value_counts(normalize=True) * 100
    print("\n--- Propor√ß√£o de Sentimentos ---")
    print(proporcao_sentimento)
    print("\nüí° Insight: A maioria dos feedbacks √© Positiva, indicando uma satisfa√ß√£o geral alta.")

**B. Categorias Mais Comentadas**

if not df.empty:
    plt.figure(figsize=(10, 5))
    sns.countplot(x='Categoria', data=df, palette='Reds_r', order=df['Categoria'].value_counts().index)
    plt.title('Foco das Categorias Mencionadas')
    plt.xlabel('Categoria')
    plt.ylabel('Contagem')
    plt.show()
    
    # Insight 2: Foco
    categoria_foco = df['Categoria'].value_counts().idxmax()
    print(f"\nüí° Insight: O principal foco do feedback dos clientes √© a categoria '{categoria_foco}', seguido de perto por 'Custo'.")

**C. Matriz de Sentimento por Categoria (O Insight de Neg√≥cio)**

if not df.empty:
    # Cria√ß√£o da tabela de conting√™ncia
    cross_tab = pd.crosstab(df['Categoria'], df['Sentimento'])
    
    # Normaliza√ß√£o por linha para ver a propor√ß√£o de sentimento dentro de cada categoria
    cross_tab_norm = cross_tab.div(cross_tab.sum(axis=1), axis=0) * 100

    print("\n--- Tabela de Conting√™ncia (Sentimento por Categoria) ---")
    display(cross_tab)

    # Plotar o gr√°fico de barras empilhadas
    plt.figure(figsize=(10, 6))
    cross_tab_norm[['Positivo', 'Negativo', 'Neutro']].plot(kind='bar', stacked=True, colormap='Spectral')
    plt.title('Propor√ß√£o de Sentimento Dentro de Cada Categoria')
    plt.ylabel('Propor√ß√£o (%)')
    plt.xlabel('Categoria')
    plt.xticks(rotation=45)
    plt.legend(title='Sentimento')
    plt.tight_layout()
    plt.show()

    # Insight 3: A√ß√£o Cr√≠tica
    negativos_custo = cross_tab.loc['Custo', 'Negativo'] if 'Custo' in cross_tab.index and 'Negativo' in cross_tab.columns else 0
    total_custo = cross_tab.loc['Custo'].sum() if 'Custo' in cross_tab.index else 0
    
    if total_custo > 0 and negativos_custo > 0:
        percentual = (negativos_custo / total_custo) * 100
        print(f"\nüî• A√á√ÉO CR√çTICA: A categoria 'Custo' possui uma alta propor√ß√£o de feedbacks Negativos ({percentual:.1f}%). Isso indica que o pre√ßo ou o valor percebido do produto √© o maior ponto de dor, e deve ser priorizado pelo time de produto/marketing.")
    else:
        print("\nO volume de dados √© muito pequeno para gerar uma A√ß√£o Cr√≠tica estatisticamente relevante.")

**5. üí° Conclus√£o e Pr√≥ximos Passos**

O pipeline **ETL com IA Generativa** validou a premissa de que √© poss√≠vel transformar **texto n√£o estruturado em insights acion√°veis** de forma r√°pida e escal√°vel.

* A fase **T (Transforma√ß√£o)**, simulada por LLM, eliminou a necessidade de horas de trabalho manual para rotular dados e gerou insights de forma imediata.
* Os dados estruturados est√£o prontos para serem ingeridos por um **Data Warehouse (Snowflake, BigQuery)** e alimentar dashboards de BI em tempo real.

O pr√≥ximo passo seria **orquestrar** a execu√ß√£o do `main_pipeline.py` diariamente usando **Apache Airflow** ou **Prefect** para automatizar a captura cont√≠nua desses insights cr√≠ticos.
